{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":"<p>A Robot Framework Listener for library agnostic self-healing and smart recovery of tests</p>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install robotframework-heal\n</code></pre>"},{"location":"#usage","title":"Usage","text":"<p>Add <code>Library    SelfHealing</code> to your Robot Framework test suite <code>*** Settings ***</code> section.</p> <pre><code>*** Settings ***\nLibrary    SelfHealing\n</code></pre> <p>Set up the following environment variables to enable the self-healing feature:</p> <ul> <li><code>LLM_API_KEY</code></li> <li><code>LLM_API_BASE</code></li> <li><code>LLM_TEXT_MODEL</code> (model used for picking final locator from proposal list)</li> <li><code>LLM_LOCATOR_MODEL</code> (model for generating locator proposals from DOM tree)</li> <li><code>LLM_VISION_MODEL</code> (not working yet)</li> </ul> <p>Interface with LLMs uses the LiteLMM API. Check the list of available Providers and how to connect to them.</p> <pre><code>*** Settings ***\nLibrary    Browser    timeout=5s\nLibrary    SelfHealing    use_llm_for_locator_proposals=True\nSuite Setup    New Browser    browser=${BROWSER}    headless=${HEADLESS}\nTest Setup    New Context    viewport={'width': 1280, 'height': 720}\nTest Teardown    Close Context\nSuite Teardown    Close Browser    ALL\n\n*** Variables ***\n${BROWSER}    chromium\n${HEADLESS}    True\n\n*** Test Cases ***\nLogin with valid credentials\n    New Page    https://the-internet.herokuapp.com/login\n    Fill Text    id=user    tomsmith\n    Fill Text    id=pass    SuperSecretPassword!\n    Click    id=loginbutton\n    Get Text    id=flash    *=    You logged into a secure area!\n</code></pre>"},{"location":"#arguments","title":"Arguments","text":"<ul> <li><code>fix</code>: Specifies the mode of operation, set to \"realtime\" for real-time healing. Default is \"realtime\".</li> <li><code>collect_locator_info</code>: Boolean flag to enable or disable the collection of locator information. Default is false.</li> <li><code>use_locator_db</code>: Boolean flag to enable or disable the use of a locator database. Default is false.</li> <li><code>use_llm_for_locator_proposals</code>: Boolean flag to enable or disable the use of a language model for generating locator proposals. Default is false.</li> <li><code>heal_assertions</code>: Boolean flag to enable or disable the healing of assertions. Default is false. (not implemented yet)</li> <li><code>locator_db_file</code>: Specifies the filename for the locator database. Default is \"locator_db.json\".</li> </ul>"},{"location":"#environment-variables","title":"Environment Variables","text":"<p>Example when running with Ollama LLM:</p> <pre><code>LLM_API_BASE=http://localhost:11434\nLLM_TEXT_MODEL=ollama_chat/llama3.1\nLLM_LOCATOR_MODEL=ollama_chat/llama3.1\nLLM_VISION_MODEL=ollama_chat/llama3.2-vision\n</code></pre> <p>Example when using OpenAI:</p> <pre><code>LLM_API_KEY=YOUR_OPENAI_API_KEY\nLLM_TEXT_MODEL=gpt-3.5-turbo\nLLM_LOCATOR_MODEL=gpt-3.5-turbo\n</code></pre>"}]}